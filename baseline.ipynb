{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10911c0b",
   "metadata": {},
   "source": [
    "## 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a662a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.models import Word2Vec\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = 'Microsoft YaHei'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11a5c5",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd338bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "data = pd.concat([train, test], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65a6cf",
   "metadata": {},
   "source": [
    "## 训练数据/测试数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3205767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = [f for f in data.columns if f not in ['是否流失','客户ID']]\n",
    "\n",
    "train = data[data['是否流失'].notnull()].reset_index(drop=True)\n",
    "test = data[data['是否流失'].isnull()].reset_index(drop=True)\n",
    "\n",
    "x_train = train[features]\n",
    "x_test = test[features]\n",
    "\n",
    "y_train = train['是否流失']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfeefd9",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[LightGBM] [Info] Number of positive: 60072, number of negative: 59928\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10515\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500600 -> initscore=0.002400\n",
      "[LightGBM] [Info] Start training from score 0.002400\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[3000]\ttraining's auc: 0.999516\tvalid_1's auc: 0.812108\n",
      "[6000]\ttraining's auc: 1\tvalid_1's auc: 0.832951\n",
      "[9000]\ttraining's auc: 1\tvalid_1's auc: 0.840899\n",
      "Early stopping, best iteration is:\n",
      "[11399]\ttraining's auc: 1\tvalid_1's auc: 0.843936\n",
      "[('当前设备使用天数', 23206.93494541943), ('当月使用分钟数与前三个月平均值的百分比变化', 18966.850461155176), ('客户生命周期内的平均每月使用分钟数', 13798.198653414845), ('每月平均使用分钟数', 13793.37155648321), ('在职总月数', 13514.45736033097), ('客户整个生命周期内的平均每月通话次数', 13169.779234770685), ('已完成语音通话的平均使用分钟数', 12717.158051796257), ('客户生命周期内的总费用', 12660.67002588883), ('当前手机价格', 12073.533231802285), ('当月费用与前三个月平均值的百分比变化', 12001.614468619227), ('计费调整后的总费用', 11994.650365594774), ('计费调整后的总分钟数', 11881.445307731628), ('使用高峰语音通话的平均不完整分钟数', 11772.639638844877), ('客户生命周期内的总使用分钟数', 11543.160580940545), ('过去六个月的平均每月使用分钟数', 11353.998523144051), ('客户生命周期内平均月费用', 11079.994449861348), ('客户生命周期内的总通话次数', 10965.192475471646), ('过去六个月的平均每月通话次数', 10816.046816661954), ('过去三个月的平均每月通话次数', 10654.587144132704), ('平均月费用', 10615.659350316972)]\n",
      "[0.8439362868562585]\n",
      "************************************ 2 ************************************\n",
      "[LightGBM] [Info] Number of positive: 59900, number of negative: 60100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10528\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 67\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499167 -> initscore=-0.003333\n",
      "[LightGBM] [Info] Start training from score -0.003333\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[3000]\ttraining's auc: 0.999531\tvalid_1's auc: 0.81211\n",
      "[6000]\ttraining's auc: 1\tvalid_1's auc: 0.832441\n"
     ]
    }
   ],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2022\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.7,\n",
    "                'bagging_fraction': 0.7,\n",
    "                'bagging_freq': 10,\n",
    "                'learning_rate': 0.2,\n",
    "                'seed': 2022,\n",
    "                'n_jobs':-1\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], \n",
    "                              categorical_feature=[], verbose_eval=3000, early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.2,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=3000, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.2, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=3000)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "        train[valid_index] = val_pred\n",
    "        test = test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "       \n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test\n",
    "    \n",
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_train, lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_train, xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_train, cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\") \n",
    "    return cat_train, cat_test\n",
    "    \n",
    "lgb_train, lgb_test = lgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9965e5a",
   "metadata": {},
   "source": [
    "## 提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['是否流失'] = lgb_test\n",
    "test[['客户ID','是否流失']].to_csv('test_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a1644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
